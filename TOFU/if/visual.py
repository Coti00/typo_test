#!/usr/bin/env python3
"""
mask_sample=0.9_word_all_words.json + mask_sample=0.9_word_selected_words_sample_details.json
ê° sample_indexë³„ë¡œ ë‹¨ì–´ si_score ë§‰ëŒ€ê·¸ë˜í”„ë¥¼ ìƒì„±
- selected_wordsëŠ” íŒŒë€ìƒ‰ ë§‰ëŒ€
- gt_tokensëŠ” ë¹¨ê°„ìƒ‰ ê¸€ì(xì¶• ë¼ë²¨)
- ë‚˜ë¨¸ì§€ëŠ” íšŒìƒ‰
- ì œëª©: Answer ì´í›„ ì „ì²´ ë¬¸ì¥ (ê¸¸ë©´ ìë™ ì¤„ë°”ê¿ˆ)
"""

import json
from collections import defaultdict
from pathlib import Path
import matplotlib.pyplot as plt
from matplotlib import rcParams
from textwrap import wrap

# âœ… í°íŠ¸ ì„¸íŒ… (í•œê¸€ ê¹¨ì§ ë°©ì§€ìš© â€” í•„ìš” ì‹œ í™œì„±í™”)
# rcParams["font.family"] = "NanumGothic"
rcParams["axes.unicode_minus"] = False


def load_json(path):
    """JSON íŒŒì¼ ë¡œë“œ"""
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)


def group_by_sample(all_words):
    """sample_index ê¸°ì¤€ìœ¼ë¡œ ë‹¨ì–´ ë¬¶ê¸°"""
    sample_data = defaultdict(list)
    for w in all_words:
        sample_idx = w["sample_index"]
        sample_data[sample_idx].append(w)
    return sample_data


def get_full_context(words_for_sample):
    """í•´ë‹¹ sample_indexì˜ full_context ë°˜í™˜"""
    for w in words_for_sample:
        if "full_context" in w and w["full_context"]:
            return w["full_context"]
    return ""


def plot_sample_words(sample_idx, words_for_sample, selected_word_list, gt_token_list, output_dir):
    """ê° sample_indexë³„ ê·¸ë˜í”„ ìƒì„±"""
    words_for_sample = sorted(words_for_sample, key=lambda x: x["word_index"])
    words = [w["word"] for w in words_for_sample]
    scores = [w["normalized_si_score"] for w in words_for_sample]

    # ìƒ‰ìƒ: ì„ íƒëœ ë‹¨ì–´ëŠ” íŒŒë‘, ê·¸ ì™¸ëŠ” íšŒìƒ‰
    colors = ["blue" if w.strip("',.?!()").lower() in selected_word_list else "gray" for w in words]

    n_words = len(words)
    width = max(8, n_words * 0.4)
    fig, ax = plt.subplots(figsize=(width, 6))
    x_pos = range(n_words)
    bars = ax.bar(x_pos, scores, color=colors)

    # ğŸ”µ gt_tokens ê¸°ì¤€
    gt_tokens_lower = [g.lower() for g in gt_token_list]
    ax.set_xticks(x_pos)
    xtick_labels = ax.set_xticklabels(words, rotation=90)

    # âœ… gt_tokensì— í¬í•¨ëœ ë‹¨ì–´ ë¼ë²¨ì„ ë¹¨ê°„ìƒ‰ + boldë¡œ í‘œì‹œ
    for lbl, w in zip(xtick_labels, words):
        word_core = w.strip("',.?!()").lower()
        if word_core in gt_tokens_lower:
            lbl.set_color("red")
            lbl.set_fontweight("bold")
        else:
            lbl.set_color("black")
            lbl.set_fontweight("normal")

    ax.set_ylabel("SI score")

    # ì œëª© ì„¤ì •
    full_context = get_full_context(words_for_sample)
    if full_context and "Answer:" in full_context:
        answer_text = full_context.split("Answer:", 1)[1].strip().replace("\n", " ")
    else:
        answer_text = full_context.replace("\n", " ")

    wrapped_title = "\n".join(wrap(answer_text, width=120))
    ax.set_title(f"[sample_index={sample_idx}] {wrapped_title}", fontsize=10, loc="center", wrap=True)

    plt.tight_layout()
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    out_path = output_dir / f"sample_{sample_idx}.png"
    fig.savefig(out_path, dpi=150)
    plt.close(fig)


def main():
    # ğŸ” íŒŒì¼ ê²½ë¡œ
    base_dir = Path("/root/tnpo/TOFU/influence_results/influence_masks/ekfac_forget10")
    all_words_path = base_dir / "mask_topk=2_word_all_words.json"
    selected_details_path = base_dir / "mask_topk=2_word_selected_words.json"
    output_dir = Path("/root/tnpo/TOFU/si_plots_highlight_selected")

    print("ğŸ“‚ JSON íŒŒì¼ ë¡œë“œ ì¤‘...")
    all_words = load_json(all_words_path)
    selected_details = load_json(selected_details_path)

    # sample_indexë³„ ë°ì´í„° ë§¤í•‘
    all_words_by_sample = group_by_sample(all_words)
    selected_by_sample = {s["sample_index"]: s.get("selected_words", []) for s in selected_details}
    gt_tokens_by_sample = {s["sample_index"]: s.get("gt_tokens", []) for s in selected_details}

    print("ğŸ“Š ê·¸ë˜í”„ ìƒì„± ì¤‘...")
    for sample_idx, words_for_sample in sorted(all_words_by_sample.items()):
        selected_words = [w.lower() for w in selected_by_sample.get(sample_idx, [])]
        gt_tokens = gt_tokens_by_sample.get(sample_idx, [])
        plot_sample_words(sample_idx, words_for_sample, selected_words, gt_tokens, output_dir)

    print(f"âœ… ì™„ë£Œ! ê·¸ë˜í”„ëŠ” '{output_dir}' í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    main()