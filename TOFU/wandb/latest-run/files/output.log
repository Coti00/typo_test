######################
Saving to:  /root/tnpo/TOFU/paper_models/final_ft_noLORA_5_epochs_inst_lr1e-05_llama2-7b_full_seed42_1/checkpoint-5000/unlearned/8GPU_tnpo_2e-05_forget10_epoch5_batch4_accum2_beta0.15_gamma1.0_grad_diff_coeff1.0_reffine_tuned_evalsteps_per_epoch_seed42_1
######################
Loading forget mask from /root/tnpo/TOFU/influence_results/influence_masks/ekfac_forget10/mask_sample=0.18_word_spacy.pt
Loaded forget mask with 400 entries
First mask shape: torch.Size([512]), dtype: torch.float32
First mask True count: 4.886499404907227 / 512
First few values: tensor([0.0000, 0.0000, 0.0000, 0.2227, 0.0000, 0.0000, 0.0000, 0.0000, 0.7773,
        0.7773, 0.7773, 0.7773, 0.0000, 0.7773, 0.7773, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000])
Total True tokens: 408.1534166634083 / 204800 (0.0020)
Forget mask set with 400 entries
First mask shape: torch.Size([512]), dtype: torch.float32
First mask sum: 4.886499404907227
Applied forget masking to 400 examples
The length of dataset: 400,
max_steps: 250,
batch_size: 4,
accumulation_step: 2.
steps_per_epoch: 50, eval_steps: 50, warmup_steps: 50
[2025-11-26 11:52:10,472] [INFO] [comm.py:821:init_distributed] cdb=None
[2025-11-26 11:52:10,473] [INFO] [comm.py:852:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
Loading from checkpoint
`torch_dtype` is deprecated! Use `dtype` instead!
[2025-11-26 11:52:12,589] [INFO] [config.py:684:__init__] Config mesh_device None world_size = 1
[2025-11-26 11:52:13,035] [INFO] [partition_parameters.py:366:__exit__] finished initializing model - num_params = 291, num_elems = 6.74B
Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:03<00:00,  1.03s/it]
[2025-11-26 11:52:16,146] [INFO] [config.py:684:__init__] Config mesh_device None world_size = 1
[2025-11-26 11:52:16,262] [INFO] [partition_parameters.py:366:__exit__] finished initializing model - num_params = 582, num_elems = 13.48B
Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:02<00:00,  1.03it/s]
######################
forget_loss: tnpo
/root/tnpo/TOFU/dataloader.py:80: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainerForgetting.__init__`. Use `processing_class` instead.
  super(CustomTrainerForgetting, self).__init__(*args, **kwargs)
[2025-11-26 11:52:19,225] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed info: version=0.17.5, git-hash=unknown, git-branch=unknown
[2025-11-26 11:52:19,225] [INFO] [config.py:684:__init__] Config mesh_device None world_size = 1
[2025-11-26 11:52:19,591] [INFO] [engine.py:1356:_configure_distributed_model] ********** distributed groups summary **********
	 self.dp_world_size=1
	 self.mp_world_size=1
	 self.seq_dp_world_size=1
	 self.sequence_parallel_size=1
***********************************************
[2025-11-26 11:52:19,592] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2025-11-26 11:52:19,593] [INFO] [logging.py:107:log_dist] [Rank 0] Creating ZeRO Offload
[2025-11-26 11:52:19,861] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[2025-11-26 11:52:19,862] [INFO] [utils.py:782:see_memory_usage] MA 25.1 GB         Max_MA 25.59 GB         CA 27.08 GB         Max_CA 27 GB
[2025-11-26 11:52:19,863] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 191.01 GB, percent = 37.9%
Parameter Offload - Persistent parameters statistics: param_count = 65, numel = 266240
[2025-11-26 11:52:20,138] [INFO] [utils.py:781:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[2025-11-26 11:52:20,139] [INFO] [utils.py:782:see_memory_usage] MA 25.1 GB         Max_MA 25.1 GB         CA 27.08 GB         Max_CA 27 GB
[2025-11-26 11:52:20,139] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 190.76 GB, percent = 37.9%
[2025-11-26 11:52:20,140] [INFO] [config.py:954:print] DeepSpeedEngine configuration:
[2025-11-26 11:52:20,141] [INFO] [config.py:958:print]   activation_checkpointing_config  {
    "partition_activations": false,
    "contiguous_memory_optimization": false,
    "cpu_checkpointing": false,
    "number_checkpoints": null,
    "synchronize_checkpoint_boundary": false,
    "profile": false
}
[2025-11-26 11:52:20,141] [INFO] [config.py:958:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'intra_op_parallelism': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}
[2025-11-26 11:52:20,141] [INFO] [config.py:958:print]   amp_enabled .................. False
[2025-11-26 11:52:20,141] [INFO] [config.py:958:print]   amp_params ................... False
[2025-11-26 11:52:20,141] [INFO] [config.py:958:print]   autotuning_config ............ {
    "enabled": false,
    "start_step": null,
    "end_step": null,
    "metric_path": null,
    "arg_mappings": null,
    "metric": "throughput",
    "model_info": null,
    "results_dir": "autotuning_results",
    "exps_dir": "autotuning_exps",
    "overwrite": true,
    "fast": true,
    "start_profile_step": 3,
    "end_profile_step": 5,
    "tuner_type": "gridsearch",
    "tuner_early_stopping": 5,
    "tuner_num_trials": 50,
    "model_info_path": null,
    "mp_size": 1,
    "max_train_batch_size": null,
    "min_train_batch_size": 1,
    "max_train_micro_batch_size_per_gpu": 1.024000e+03,
    "min_train_micro_batch_size_per_gpu": 1,
    "num_tuning_micro_batch_sizes": 3
}
[2025-11-26 11:52:20,142] [INFO] [config.py:958:print]   bfloat16_config .............. enabled=True immediate_grad_update=False check_grad_overflow=False
[2025-11-26 11:52:20,142] [INFO] [config.py:958:print]   checkpoint_config ............ {'tag_validation': 'WARN', 'checkpoint_serialization': True, 'writer': None}
[2025-11-26 11:52:20,142] [INFO] [config.py:958:print]   checkpoint_parallel_write_pipeline  False
[2025-11-26 11:52:20,142] [INFO] [config.py:958:print]   checkpoint_tag_validation_enabled  True
[2025-11-26 11:52:20,142] [INFO] [config.py:958:print]   checkpoint_tag_validation_fail  False
[2025-11-26 11:52:20,142] [INFO] [config.py:958:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x75a23daa05b0>
[2025-11-26 11:52:20,142] [INFO] [config.py:958:print]   communication_data_type ...... None
[2025-11-26 11:52:20,142] [INFO] [config.py:958:print]   compile_config ............... deepcompile=False free_activation=False offload_activation=False offload_opt_states=False double_buffer=True symmetric_memory=False debug_log=False offload_parameters=False sync_before_reduce=False sync_after_reduce=False sync_before_allgather=False sync_after_allgather=False keep_int_input_tensors=True keep_all_input_tensors=False
[2025-11-26 11:52:20,142] [INFO] [config.py:958:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2025-11-26 11:52:20,142] [INFO] [config.py:958:print]   curriculum_enabled_legacy .... False
[2025-11-26 11:52:20,142] [INFO] [config.py:958:print]   curriculum_params_legacy ..... False
[2025-11-26 11:52:20,142] [INFO] [config.py:958:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'pin_memory': False, 'curriculum_learning': {'enabled': False}, 'dynamic_batching': {'enabled': False, 'lr_scaling_method': 'linear', 'min_batch_size': 1, 'max_batch_size': None, 'sequence_picking_order': 'dataloader', 'verbose': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2025-11-26 11:52:20,142] [INFO] [config.py:958:print]   data_efficiency_enabled ...... False
[2025-11-26 11:52:20,142] [INFO] [config.py:958:print]   dataloader_drop_last ......... False
[2025-11-26 11:52:20,143] [INFO] [config.py:958:print]   disable_allgather ............ False
[2025-11-26 11:52:20,143] [INFO] [config.py:958:print]   dump_state ................... False
[2025-11-26 11:52:20,143] [INFO] [config.py:958:print]   eigenvalue_enabled ........... False
[2025-11-26 11:52:20,143] [INFO] [config.py:958:print]   eigenvalue_gas_boundary_resolution  1
[2025-11-26 11:52:20,143] [INFO] [config.py:958:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2025-11-26 11:52:20,143] [INFO] [config.py:958:print]   eigenvalue_layer_num ......... 0
[2025-11-26 11:52:20,143] [INFO] [config.py:958:print]   eigenvalue_max_iter .......... 100
[2025-11-26 11:52:20,143] [INFO] [config.py:958:print]   eigenvalue_stability ......... 1e-06
[2025-11-26 11:52:20,143] [INFO] [config.py:958:print]   eigenvalue_tol ............... 0.01
[2025-11-26 11:52:20,143] [INFO] [config.py:958:print]   eigenvalue_verbose ........... False
[2025-11-26 11:52:20,143] [INFO] [config.py:958:print]   elasticity_enabled ........... False
[2025-11-26 11:52:20,143] [INFO] [config.py:958:print]   float16_config ............... enabled=False auto_cast=False loss_scale=0.0 initial_scale_power=16 loss_scale_window=1000 hysteresis=2 consecutive_hysteresis=False min_loss_scale=1 fp16_master_weights_and_grads=False
[2025-11-26 11:52:20,143] [INFO] [config.py:958:print]   flops_profiler_config ........ {
    "enabled": false,
    "recompute_fwd_factor": 0.0,
    "profile_step": 1,
    "module_depth": -1,
    "top_modules": 1,
    "detailed": true,
    "output_file": null
}
[2025-11-26 11:52:20,143] [INFO] [config.py:958:print]   global_rank .................. 0
[2025-11-26 11:52:20,143] [INFO] [config.py:958:print]   grad_accum_dtype ............. None
[2025-11-26 11:52:20,143] [INFO] [config.py:958:print]   gradient_accumulation_steps .. 2
[2025-11-26 11:52:20,144] [INFO] [config.py:958:print]   gradient_clipping ............ 1.0
[2025-11-26 11:52:20,144] [INFO] [config.py:958:print]   gradient_predivide_factor .... 1.0
[2025-11-26 11:52:20,144] [INFO] [config.py:958:print]   graph_harvesting ............. False
[2025-11-26 11:52:20,144] [INFO] [config.py:958:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2025-11-26 11:52:20,144] [INFO] [config.py:958:print]   load_universal_checkpoint .... False
[2025-11-26 11:52:20,144] [INFO] [config.py:958:print]   memory_breakdown ............. False
[2025-11-26 11:52:20,144] [INFO] [config.py:958:print]   mics_hierarchial_params_gather  False
[2025-11-26 11:52:20,144] [INFO] [config.py:958:print]   mics_shard_size .............. -1
[2025-11-26 11:52:20,144] [INFO] [config.py:958:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')
[2025-11-26 11:52:20,144] [INFO] [config.py:958:print]   nebula_config ................ {
    "enabled": false,
    "persistent_storage_path": null,
    "persistent_time_interval": 100,
    "num_of_version_in_retention": 2,
    "enable_nebula_load": true,
    "load_path": null
}
[2025-11-26 11:52:20,144] [INFO] [config.py:958:print]   optimizer_legacy_fusion ...... False
[2025-11-26 11:52:20,144] [INFO] [config.py:958:print]   optimizer_name ............... None
[2025-11-26 11:52:20,144] [INFO] [config.py:958:print]   optimizer_params ............. None
[2025-11-26 11:52:20,144] [INFO] [config.py:958:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2025-11-26 11:52:20,144] [INFO] [config.py:958:print]   pld_enabled .................. False
[2025-11-26 11:52:20,145] [INFO] [config.py:958:print]   pld_params ................... False
[2025-11-26 11:52:20,145] [INFO] [config.py:958:print]   prescale_gradients ........... False
[2025-11-26 11:52:20,145] [INFO] [config.py:958:print]   scheduler_name ............... None
[2025-11-26 11:52:20,145] [INFO] [config.py:958:print]   scheduler_params ............. None
[2025-11-26 11:52:20,145] [INFO] [config.py:958:print]   seq_parallel_communication_data_type  torch.float32
[2025-11-26 11:52:20,145] [INFO] [config.py:958:print]   sparse_attention ............. None
[2025-11-26 11:52:20,145] [INFO] [config.py:958:print]   sparse_gradients_enabled ..... False
[2025-11-26 11:52:20,145] [INFO] [config.py:958:print]   steps_per_print .............. inf
[2025-11-26 11:52:20,145] [INFO] [config.py:958:print]   tensor_parallel_config ....... dtype=torch.float16 autotp_size=0 tp_overlap_comm=False tensor_parallel=TPConfig(tp_size=1, tp_grain_size=1, mpu=None, tp_group=None) injection_policy_tuple=None keep_module_on_host=False replace_with_kernel_inject=False
[2025-11-26 11:52:20,145] [INFO] [config.py:958:print]   timers_config ................ enabled=True synchronized=True
[2025-11-26 11:52:20,145] [INFO] [config.py:958:print]   torch_autocast_dtype ......... None
[2025-11-26 11:52:20,145] [INFO] [config.py:958:print]   torch_autocast_enabled ....... False
[2025-11-26 11:52:20,145] [INFO] [config.py:958:print]   torch_autocast_lower_precision_safe_modules  None
[2025-11-26 11:52:20,145] [INFO] [config.py:958:print]   train_batch_size ............. 8
[2025-11-26 11:52:20,145] [INFO] [config.py:958:print]   train_micro_batch_size_per_gpu  4
[2025-11-26 11:52:20,145] [INFO] [config.py:958:print]   use_data_before_expert_parallel_  False
[2025-11-26 11:52:20,145] [INFO] [config.py:958:print]   use_node_local_storage ....... False
[2025-11-26 11:52:20,146] [INFO] [config.py:958:print]   wall_clock_breakdown ......... False
[2025-11-26 11:52:20,146] [INFO] [config.py:958:print]   weight_quantization_config ... None
[2025-11-26 11:52:20,146] [INFO] [config.py:958:print]   world_size ................... 1
[2025-11-26 11:52:20,146] [INFO] [config.py:958:print]   zero_allow_untested_optimizer  False
[2025-11-26 11:52:20,146] [INFO] [config.py:958:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100000000, max_in_cpu=1000000000, pin_memory=True) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='none', nvme_path=None, buffer_count=4, pin_memory=True, pipeline_read=False, pipeline_write=False, fast_init=False, ratio=1.0) zenflow=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=100000000 max_reuse_distance=100000000 gather_16bit_weights_on_model_save=True module_granularity_threshold=0 use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False zeropp_loco_param=None mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True log_trace_cache_warnings=False
[2025-11-26 11:52:20,146] [INFO] [config.py:958:print]   zero_enabled ................. True
[2025-11-26 11:52:20,146] [INFO] [config.py:958:print]   zero_force_ds_cpu_optimizer .. True
[2025-11-26 11:52:20,146] [INFO] [config.py:958:print]   zero_optimization_stage ...... 3
[2025-11-26 11:52:20,146] [INFO] [config.py:944:print_user_config]   json = {
    "zero_optimization": {
        "stage": 3,
        "offload_optimizer": {
            "device": "none",
            "pin_memory": true
        },
        "offload_param": {
            "device": "none",
            "pin_memory": true
        },
        "overlap_comm": true,
        "contiguous_gradients": true,
        "sub_group_size": 1.000000e+09,
        "reduce_bucket_size": "auto",
        "stage3_prefetch_bucket_size": "auto",
        "stage3_param_persistence_threshold": "auto",
        "stage3_max_live_parameters": 1.000000e+08,
        "stage3_max_reuse_distance": 1.000000e+08,
        "stage3_gather_16bit_weights_on_model_save": true
    },
    "train_batch_size": 8,
    "train_micro_batch_size_per_gpu": 4,
    "gradient_accumulation_steps": 2,
    "bf16": {
        "enabled": true
    },
    "gradient_clipping": 1.0,
    "steps_per_print": inf,
    "wall_clock_breakdown": false,
    "fp16": {
        "enabled": false
    },
    "zero_optimization.reduce_bucket_size": 1.677722e+07,
    "zero_optimization.stage3_param_persistence_threshold": 4.096000e+04,
    "zero_optimization.stage3_prefetch_bucket_size": 1.509949e+07,
    "optimizer": {
        "type": null
    }
}
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 50256, 'bos_token_id': 50256, 'pad_token_id': 50256}.
Generator........Epoch-0
[2025-11-26 11:52:20,381][accelerate.accelerator][WARNING] - Gradient accumulation steps mismatch: GradientAccumulationPlugin has 1, DeepSpeed config has 2. Using DeepSpeed's value.
[2025-11-26 11:52:20,830] [WARNING] [engine.py:1390:_do_optimizer_sanity_check] **** You are using ZeRO with an untested optimizer, proceed with caution *****
Parameter Offload - Persistent parameters statistics: param_count = 65, numel = 266240
Error executing job with overrides: ['split=forget10', 'model_family=phi', 'lr=2e-5', 'forget_loss=tnpo', 'beta=0.15', 'gamma=1.0', 'forget_mask_path="/root/tnpo/TOFU/influence_results/influence_masks/ekfac_forget10/mask_sample=0.18_word_spacy.pt"', 'batch_size=4', 'gradient_accumulation_steps=2', 'num_epochs=5', 'weight_decay=0.01', 'seed=42']
Traceback (most recent call last):
  File "/root/tnpo/TOFU/forget.py", line 271, in main
    trainer.train()
  File "/opt/conda/envs/tofu/lib/python3.10/site-packages/transformers/trainer.py", line 2326, in train
    return inner_training_loop(
  File "/opt/conda/envs/tofu/lib/python3.10/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    model, self.optimizer = self.accelerator.prepare(self.model, self.optimizer)
  File "/opt/conda/envs/tofu/lib/python3.10/site-packages/accelerate/accelerator.py", line 1547, in prepare
    result = self._prepare_deepspeed(*args)
  File "/opt/conda/envs/tofu/lib/python3.10/site-packages/accelerate/accelerator.py", line 2290, in _prepare_deepspeed
    engine, optimizer, _, lr_scheduler = ds_initialize(**kwargs)
  File "/opt/conda/envs/tofu/lib/python3.10/site-packages/deepspeed/__init__.py", line 193, in initialize
    engine = DeepSpeedEngine(args=args,
  File "/opt/conda/envs/tofu/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 345, in __init__
    self._configure_optimizer(optimizer, model_parameters)
  File "/opt/conda/envs/tofu/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 1460, in _configure_optimizer
    self.optimizer = self._configure_zero_optimizer(basic_optimizer)
  File "/opt/conda/envs/tofu/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 1807, in _configure_zero_optimizer
    optimizer = DeepSpeedZeroOptimizer_Stage3(
  File "/opt/conda/envs/tofu/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py", line 424, in __init__
    self._setup_for_real_optimizer()
  File "/opt/conda/envs/tofu/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py", line 568, in _setup_for_real_optimizer
    self.grad_partitions_flat_buffer: Tensor = torch.zeros(sum(p.partition_numel() for p in all_params),
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 12.55 GiB. GPU 0 has a total capacity of 139.80 GiB of which 6.07 GiB is free. Process 10633 has 61.96 GiB memory in use. Process 54128 has 14.10 GiB memory in use. Process 183825 has 54.30 GiB memory in use. Of the allocated memory 50.24 GiB is allocated by PyTorch, and 2.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
